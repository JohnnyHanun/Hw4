{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hw4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNnZPLTtjGa34TXcxiQNHHE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JohnnyHanun/Hw4/blob/main/Hw4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvSgvhmLAsib",
        "outputId": "13c4d694-4846-47b0-d805-d002439e8c30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting facenet-pytorch\n",
            "  Downloading facenet_pytorch-2.5.2-py3-none-any.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 13.3 MB/s \n",
            "\u001b[?25hCollecting mmcv\n",
            "  Downloading mmcv-1.5.2.tar.gz (536 kB)\n",
            "\u001b[K     |████████████████████████████████| 536 kB 57.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from facenet-pytorch) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from facenet-pytorch) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from facenet-pytorch) (2.23.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from facenet-pytorch) (0.12.0+cu113)\n",
            "Collecting addict\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mmcv) (21.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from mmcv) (3.13)\n",
            "Collecting yapf\n",
            "  Downloading yapf-0.32.0-py2.py3-none-any.whl (190 kB)\n",
            "\u001b[K     |████████████████████████████████| 190 kB 48.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->mmcv) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->facenet-pytorch) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->facenet-pytorch) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->facenet-pytorch) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->facenet-pytorch) (3.0.4)\n",
            "Requirement already satisfied: torch==1.11.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->facenet-pytorch) (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchvision->facenet-pytorch) (4.2.0)\n",
            "Building wheels for collected packages: mmcv\n",
            "  Building wheel for mmcv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mmcv: filename=mmcv-1.5.2-py2.py3-none-any.whl size=817819 sha256=f3fe015779909e0ddd0c2499b1e0931cebb8513b925485b102a2b2373db6155e\n",
            "  Stored in directory: /root/.cache/pip/wheels/f7/60/be/c3c92db989db1ca7055973f5913815c117b6a270e69e65b1d1\n",
            "Successfully built mmcv\n",
            "Installing collected packages: yapf, addict, mmcv, facenet-pytorch\n",
            "Successfully installed addict-2.4.0 facenet-pytorch-2.5.2 mmcv-1.5.2 yapf-0.32.0\n"
          ]
        }
      ],
      "source": [
        "! pip install facenet-pytorch mmcv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xPZ3zUL_q6v"
      },
      "source": [
        "# Face tracking pipeline\n",
        "\n",
        "The following example illustrates how to use the `facenet_pytorch` python package to perform face detection and tracking on an image dataset using MTCNN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlU9SZRx_q61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65137b57-35ab-474d-d3a3-5b181d903fcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n"
          ]
        }
      ],
      "source": [
        "from facenet_pytorch import MTCNN\n",
        "import torch\n",
        "import numpy as np\n",
        "import mmcv, cv2\n",
        "from PIL import Image, ImageDraw\n",
        "from IPython import display"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRQxFNHs_q62"
      },
      "source": [
        "#### Determine if an nvidia GPU is available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHXOvDvH_q63",
        "outputId": "dd6710ed-500d-4693-b4fc-65ec0ddd085f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on device: cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print('Running on device: {}'.format(device))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjR_PmrN_q64"
      },
      "source": [
        "#### Define MTCNN module\n",
        "\n",
        "Note that, since MTCNN is a collection of neural nets and other code, the device must be passed in the following way to enable copying of objects when needed internally.\n",
        "\n",
        "See `help(MTCNN)` for more details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHu82Eis_q65"
      },
      "outputs": [],
      "source": [
        "mtcnn = MTCNN(keep_all=True, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDNQuv9l_q65"
      },
      "source": [
        "#### Get a sample video\n",
        "\n",
        "We begin by loading a video with some faces in it. The `mmcv` PyPI package by mmlabs is used to read the video frames (it can be installed with `pip install mmcv`). Frames are then converted to PIL images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1jxcHrQAHEr",
        "outputId": "cb66065a-34fe-4725-9f11-710577777ade"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-31 15:47:55--  https://github.com/timesler/facenet-pytorch/raw/master/examples/video.mp4\n",
            "Resolving github.com (github.com)... 140.82.121.3\n",
            "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/timesler/facenet-pytorch/master/examples/video.mp4 [following]\n",
            "--2022-05-31 15:47:55--  https://raw.githubusercontent.com/timesler/facenet-pytorch/master/examples/video.mp4\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2411585 (2.3M) [application/octet-stream]\n",
            "Saving to: ‘video.mp4’\n",
            "\n",
            "video.mp4           100%[===================>]   2.30M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2022-05-31 15:47:55 (94.4 MB/s) - ‘video.mp4’ saved [2411585/2411585]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "! wget -nc https://github.com/timesler/facenet-pytorch/raw/master/examples/video.mp4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nif_UVzYDJ6x"
      },
      "outputs": [],
      "source": [
        "from base64 import b64encode\n",
        "from IPython.display import HTML\n",
        "\n",
        "def displayVideo(file_path):\n",
        "  mp4 = open(file_path, 'rb').read()\n",
        "  data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "  return HTML(\"\"\"\n",
        "      <video width=800 controls>\n",
        "            <source src=\"%s\" type=\"video/mp4\">\n",
        "      </video>\n",
        "    \"\"\" % data_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4DHWHe7G_q66",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "video = mmcv.VideoReader('video.mp4')\n",
        "frames = [Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)) for frame in video]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "displayVideo(\"video.mp4\")"
      ],
      "metadata": {
        "id": "539HJZ0EKuyK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "outputId": "98699ed2-e779-47e3-a416-ea7eea3ecefd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-msb23F__q67"
      },
      "source": [
        "#### Run video through MTCNN\n",
        "\n",
        "We iterate through each frame, detect faces, and draw their bounding boxes on the video frames."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0qJA4AP_q67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32f769b3-b116-4249-b469-6fffb4d4425d"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\rTracking frame: 1"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:780: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n",
            "  warnings.warn(\"Note that order of the arguments: ceil_mode and return_indices will change\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tracking frame: 98"
          ]
        }
      ],
      "source": [
        "frames_tracked = []\n",
        "for i, frame in enumerate(frames):\n",
        "    print('\\rTracking frame: {}'.format(i + 1), end='')\n",
        "    \n",
        "    # Detect faces\n",
        "    boxes, _ = mtcnn.detect(frame)\n",
        "    \n",
        "    # Draw faces\n",
        "    frame_draw = frame.copy()\n",
        "    draw = ImageDraw.Draw(frame_draw)\n",
        "    for box in boxes:\n",
        "        draw.rectangle(box.tolist(), outline=(255, 0, 0), width=6)\n",
        "    \n",
        "    # Add to frame list\n",
        "    frames_tracked.append(frame_draw.resize((640, 360), Image.BILINEAR))\n",
        "print('\\nDone')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2816Ff6B_q69"
      },
      "source": [
        "#### Save tracked video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dw7wWHv8_q69"
      },
      "outputs": [],
      "source": [
        "dim = frames_tracked[0].size\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')    \n",
        "video_tracked = cv2.VideoWriter('video_tracked.avi', fourcc, 25.0, dim)\n",
        "for frame in frames_tracked:\n",
        "    video_tracked.write(cv2.cvtColor(np.array(frame), cv2.COLOR_RGB2BGR))\n",
        "video_tracked.release()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install ffmpeg-python"
      ],
      "metadata": {
        "id": "AclzbDxjQy0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ffmpeg\n",
        "(\n",
        "    ffmpeg\n",
        "    .input('video_tracked.avi')\n",
        "    .output('video_tracked.mp4')\n",
        "    .run()\n",
        ")"
      ],
      "metadata": {
        "id": "Vn-y4eWaRJyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ECXpPY__q68"
      },
      "source": [
        "#### Display detections"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "displayVideo(\"video_tracked.mp4\")"
      ],
      "metadata": {
        "id": "Y0KONuFjG22I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}